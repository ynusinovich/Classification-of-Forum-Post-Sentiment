{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Web APIs & NLP\n",
    "# Notebook 4: Modeling\n",
    "\n",
    "https://github.com/pushshift/api<br>\n",
    "https://api.pushshift.io/reddit/search/comment/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- [Import Libraries and Data](#Import-Libraries-and-Data)\n",
    "- [Run Classification Models with Hyperparameter Tuning](#Run-Classification-Models-with-Hyperparameter-Tuning)\n",
    "- [Save Best Model](#Save-Best-Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.max_columns', 40)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"../datasets/X_train\", squeeze = True)\n",
    "X_test = pd.read_csv(\"../datasets/X_test\", squeeze = True)\n",
    "y_train = pd.read_csv(\"../datasets/y_train\", squeeze = True)\n",
    "y_test = pd.read_csv(\"../datasets/y_test\", squeeze = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Classification Models with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Non-optimal hyperparameters are removed after each run in order to speed up re-runs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models with Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 4500,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_cvec_lr = Pipeline([(\"cvec\", CountVectorizer()),\n",
    "                         (\"lr\", LogisticRegression(max_iter = 1000))])\n",
    "pipe_cvec_lr_params = {\"cvec__max_features\": [4500],\n",
    "                       \"cvec__ngram_range\": [(1,1)],\n",
    "                       \"cvec__stop_words\": [\"english\", None]}\n",
    "gs_cvec_lr = GridSearchCV(pipe_cvec_lr,\n",
    "                          param_grid = pipe_cvec_lr_params,\n",
    "                          cv = 5, n_jobs = -1)\n",
    "gs_cvec_lr.fit(X_train, y_train)\n",
    "gs_cvec_lr_model = gs_cvec_lr.best_estimator_\n",
    "gs_cvec_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 6000,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'cvec__stop_words': 'english'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not likely the best Naive Bayes model for Count Vectorizer or Tfidf Vectorizer\n",
    "pipe_cvec_bnb = Pipeline([(\"cvec\", CountVectorizer()),\n",
    "                          (\"ft\", FunctionTransformer(lambda x: x.todense(), accept_sparse = True)),\n",
    "                          (\"bnb\", BernoulliNB())])\n",
    "pipe_cvec_bnb_params = {\"cvec__max_features\": [6000],\n",
    "                        \"cvec__ngram_range\": [(1,2)],\n",
    "                        \"cvec__stop_words\": [\"english\"]}\n",
    "gs_cvec_bnb = GridSearchCV(pipe_cvec_bnb,\n",
    "                           param_grid = pipe_cvec_bnb_params,\n",
    "                           cv = 5, n_jobs = -1)\n",
    "gs_cvec_bnb.fit(X_train, y_train)\n",
    "gs_cvec_bnb_model = gs_cvec_bnb.best_estimator_\n",
    "gs_cvec_bnb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 7500,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# likely the best Naive Bayes model for Count Vectorizer\n",
    "pipe_cvec_mnb = Pipeline([(\"cvec\", CountVectorizer()),\n",
    "                          (\"ft\", FunctionTransformer(lambda x: x.todense(), accept_sparse = True)),\n",
    "                          (\"mnb\", MultinomialNB())])\n",
    "pipe_cvec_mnb_params = {\"cvec__max_features\": [7500],\n",
    "                        \"cvec__ngram_range\": [(1,1)],\n",
    "                        \"cvec__stop_words\": [None]}\n",
    "gs_cvec_mnb = GridSearchCV(pipe_cvec_mnb,\n",
    "                           param_grid = pipe_cvec_mnb_params,\n",
    "                           cv = 5, n_jobs = -1)\n",
    "gs_cvec_mnb.fit(X_train, y_train)\n",
    "gs_cvec_mnb_model = gs_cvec_mnb.best_estimator_\n",
    "gs_cvec_mnb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 3000,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'cvec__stop_words': 'english'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not likely the best Naive Bayes model for Count Vectorizer\n",
    "pipe_cvec_gnb = Pipeline([(\"cvec\", CountVectorizer()),\n",
    "                          (\"ft\", FunctionTransformer(lambda x: x.todense(), accept_sparse = True)),\n",
    "                          (\"gnb\", GaussianNB())])\n",
    "pipe_cvec_gnb_params = {\"cvec__max_features\": [3000],\n",
    "                        \"cvec__ngram_range\": [(1,2)],\n",
    "                        \"cvec__stop_words\": [\"english\"]}\n",
    "gs_cvec_gnb = GridSearchCV(pipe_cvec_gnb,\n",
    "                           param_grid = pipe_cvec_gnb_params,\n",
    "                           cv = 5, n_jobs = -1)\n",
    "gs_cvec_gnb.fit(X_train, y_train)\n",
    "gs_cvec_gnb_model = gs_cvec_gnb.best_estimator_\n",
    "gs_cvec_gnb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 500,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'cvec__stop_words': None,\n",
       " 'knn__n_neighbors': 15}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_cvec_knn = Pipeline([(\"cvec\", CountVectorizer()),\n",
    "                          (\"ft\", FunctionTransformer(lambda x: x.todense(), accept_sparse = True)),\n",
    "                          (\"knn\", KNeighborsClassifier())])\n",
    "pipe_cvec_knn_params = {\"cvec__max_features\": [500],\n",
    "                        \"cvec__ngram_range\": [(1,2)],\n",
    "                        \"cvec__stop_words\": [None],\n",
    "                        \"knn__n_neighbors\": [15]}\n",
    "gs_cvec_knn = GridSearchCV(pipe_cvec_knn,\n",
    "                           param_grid = pipe_cvec_knn_params,\n",
    "                           cv = 5, n_jobs = -1)\n",
    "gs_cvec_knn.fit(X_train, y_train)\n",
    "gs_cvec_knn_model = gs_cvec_knn.best_estimator_\n",
    "gs_cvec_knn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 8000,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english',\n",
       " 'dt__max_depth': 29,\n",
       " 'dt__min_samples_leaf': 1,\n",
       " 'dt__min_samples_split': 10}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not likely optimal without bagging or boosting\n",
    "pipe_cvec_dt = Pipeline([(\"cvec\", CountVectorizer()),\n",
    "                         (\"ft\", FunctionTransformer(lambda x: x.todense(), accept_sparse = True)),\n",
    "                         (\"dt\", DecisionTreeClassifier())])\n",
    "pipe_cvec_dt_params = {\"cvec__max_features\": [8000],\n",
    "                       \"cvec__ngram_range\": [(1,1)],\n",
    "                       \"cvec__stop_words\": [\"english\"],\n",
    "                       \"dt__max_depth\": [29],\n",
    "                       \"dt__min_samples_split\": [10],\n",
    "                       \"dt__min_samples_leaf\": [1]}\n",
    "gs_cvec_dt = GridSearchCV(pipe_cvec_dt,\n",
    "                          param_grid = pipe_cvec_dt_params,\n",
    "                          cv = 5, n_jobs = -1)\n",
    "gs_cvec_dt.fit(X_train, y_train)\n",
    "gs_cvec_dt_model = gs_cvec_dt.best_estimator_\n",
    "gs_cvec_dt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bag__base_estimator__max_depth': 29,\n",
       " 'bag__base_estimator__min_samples_leaf': 1,\n",
       " 'bag__base_estimator__min_samples_split': 10,\n",
       " 'bag__max_features': 0.3,\n",
       " 'bag__max_samples': 0.5,\n",
       " 'bag__n_estimators': 15,\n",
       " 'cvec__max_features': 8000,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_cvec_dt_bag = Pipeline([(\"cvec\", CountVectorizer()),\n",
    "                             (\"ft\", FunctionTransformer(lambda x: x.todense(), accept_sparse = True)),\n",
    "                             (\"bag\", BaggingClassifier(base_estimator = DecisionTreeClassifier()))])\n",
    "pipe_cvec_dt_bag_params = {\"bag__base_estimator__max_depth\": [29],\n",
    "                           \"bag__base_estimator__min_samples_leaf\": [1],\n",
    "                           \"bag__base_estimator__min_samples_split\": [10],\n",
    "                           'cvec__max_features': [8000],\n",
    "                           'cvec__ngram_range': [(1, 1)],\n",
    "                           'cvec__stop_words': ['english'],\n",
    "                           \"bag__n_estimators\": [15],\n",
    "                           \"bag__max_samples\": [.5],\n",
    "                           \"bag__max_features\": [.3]}\n",
    "gs_cvec_dt_bag = GridSearchCV(pipe_cvec_dt_bag,\n",
    "                              param_grid = pipe_cvec_dt_bag_params,\n",
    "                              cv = 5, n_jobs = -1)\n",
    "gs_cvec_dt_bag.fit(X_train, y_train)\n",
    "gs_cvec_dt_bag_model = gs_cvec_dt_bag.best_estimator_\n",
    "gs_cvec_dt_bag.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 7000,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english',\n",
       " 'rf__max_depth': None,\n",
       " 'rf__n_estimators': 100}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_cvec_rf = Pipeline([(\"cvec\", CountVectorizer()),\n",
    "                         (\"ft\", FunctionTransformer(lambda x: x.todense(), accept_sparse = True)),\n",
    "                         (\"rf\", RandomForestClassifier())])\n",
    "pipe_cvec_rf_params = {'cvec__max_features': [7000],\n",
    "                       'cvec__ngram_range': [(1, 1)],\n",
    "                       'cvec__stop_words': ['english'],\n",
    "                       \"rf__n_estimators\": [100],\n",
    "                       \"rf__max_depth\": [None]}\n",
    "gs_cvec_rf = GridSearchCV(pipe_cvec_rf,\n",
    "                          param_grid = pipe_cvec_rf_params,\n",
    "                          cv = 5, n_jobs = -1)\n",
    "gs_cvec_rf.fit(X_train, y_train)\n",
    "gs_cvec_rf_model = gs_cvec_rf.best_estimator_\n",
    "gs_cvec_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 6000,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english',\n",
       " 'et__max_depth': None,\n",
       " 'et__n_estimators': 150}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_cvec_et = Pipeline([(\"cvec\", CountVectorizer()),\n",
    "                         (\"ft\", FunctionTransformer(lambda x: x.todense(), accept_sparse = True)),\n",
    "                         (\"et\", ExtraTreesClassifier())])\n",
    "pipe_cvec_et_params = {'cvec__max_features': [6000],\n",
    "                       'cvec__ngram_range': [(1, 1)],\n",
    "                       'cvec__stop_words': ['english'],\n",
    "                       \"et__n_estimators\": [150],\n",
    "                       \"et__max_depth\": [None]}\n",
    "gs_cvec_et = GridSearchCV(pipe_cvec_et,\n",
    "                          param_grid = pipe_cvec_et_params,\n",
    "                          cv = 5, n_jobs = -1)\n",
    "gs_cvec_et.fit(X_train, y_train)\n",
    "gs_cvec_et_model = gs_cvec_et.best_estimator_\n",
    "gs_cvec_et.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ada__base_estimator__max_depth': 2,\n",
       " 'ada__n_estimators': 150,\n",
       " 'cvec__max_features': 8000,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_cvec_ada = Pipeline([(\"cvec\", CountVectorizer()),\n",
    "                          (\"ft\", FunctionTransformer(lambda x: x.todense(), accept_sparse = True)),\n",
    "                          (\"ada\", AdaBoostClassifier(base_estimator = DecisionTreeClassifier()))])\n",
    "pipe_cvec_ada_params = {\"ada__base_estimator__max_depth\": [2],\n",
    "                        'cvec__max_features': [8000],\n",
    "                        'cvec__ngram_range': [(1, 1)],\n",
    "                        'cvec__stop_words': ['english'],\n",
    "                        \"ada__n_estimators\": [150]}\n",
    "gs_cvec_ada = GridSearchCV(pipe_cvec_ada,\n",
    "                           param_grid = pipe_cvec_ada_params,\n",
    "                           cv = 5, n_jobs = -1)\n",
    "gs_cvec_ada.fit(X_train, y_train)\n",
    "gs_cvec_ada_model = gs_cvec_ada.best_estimator_\n",
    "gs_cvec_ada.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 7000,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english',\n",
       " 'svc__C': 10}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_cvec_svc = Pipeline([(\"cvec\", CountVectorizer()),\n",
    "                          (\"ft\", FunctionTransformer(lambda x: x.todense(), accept_sparse = True)),\n",
    "                          (\"svc\", SVC(probability = True))])\n",
    "pipe_cvec_svc_params = {'cvec__max_features': [7000],\n",
    "                        'cvec__ngram_range': [(1, 1)],\n",
    "                        'cvec__stop_words': ['english'],\n",
    "                        \"svc__C\": [10]}\n",
    "gs_cvec_svc = GridSearchCV(pipe_cvec_svc,\n",
    "                           param_grid = pipe_cvec_svc_params,\n",
    "                           cv = 5, n_jobs = -1)\n",
    "gs_cvec_svc.fit(X_train, y_train)\n",
    "gs_cvec_svc_model = gs_cvec_svc.best_estimator_\n",
    "gs_cvec_svc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models with Tfidf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf__max_features': 5500,\n",
       " 'tfidf__ngram_range': (1, 1),\n",
       " 'tfidf__stop_words': None}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_tfidf_lr = Pipeline([(\"tfidf\", TfidfVectorizer()),\n",
    "                          (\"lr\", LogisticRegression(max_iter = 1000))])\n",
    "pipe_tfidf_lr_params = {\"tfidf__max_features\": [5500],\n",
    "                        \"tfidf__ngram_range\": [(1,1)],\n",
    "                        \"tfidf__stop_words\": [None]}\n",
    "gs_tfidf_lr = GridSearchCV(pipe_tfidf_lr,\n",
    "                           param_grid = pipe_tfidf_lr_params,\n",
    "                           cv = 5, n_jobs = -1)\n",
    "gs_tfidf_lr.fit(X_train, y_train)\n",
    "gs_tfidf_lr_model = gs_tfidf_lr.best_estimator_\n",
    "gs_tfidf_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf__max_features': 3000,\n",
       " 'tfidf__ngram_range': (1, 2),\n",
       " 'tfidf__stop_words': 'english'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not likely the best Naive Bayes model for Count Vectorizer or Tfidf Vectorizer\n",
    "pipe_tfidf_bnb = Pipeline([(\"tfidf\", TfidfVectorizer()),\n",
    "                         (\"ft\", FunctionTransformer(lambda x: x.todense(), accept_sparse = True)),\n",
    "                         (\"bnb\", BernoulliNB())])\n",
    "pipe_tfidf_bnb_params = {\"tfidf__max_features\": [3000],\n",
    "                         \"tfidf__ngram_range\": [(1,2)],\n",
    "                         \"tfidf__stop_words\": [\"english\"]}\n",
    "gs_tfidf_bnb = GridSearchCV(pipe_tfidf_bnb,\n",
    "                            param_grid = pipe_tfidf_bnb_params,\n",
    "                            cv = 5, n_jobs = -1)\n",
    "gs_tfidf_bnb.fit(X_train, y_train)\n",
    "gs_tfidf_bnb_model = gs_tfidf_bnb.best_estimator_\n",
    "gs_tfidf_bnb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf__max_features': 3000,\n",
       " 'tfidf__ngram_range': (1, 2),\n",
       " 'tfidf__stop_words': 'english'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not likely the best Naive Bayes model for Tfidf Vectorizer\n",
    "pipe_tfidf_mnb = Pipeline([(\"tfidf\", TfidfVectorizer()),\n",
    "                         (\"ft\", FunctionTransformer(lambda x: x.todense(), accept_sparse = True)),\n",
    "                         (\"mnb\", MultinomialNB())])\n",
    "pipe_tfidf_mnb_params = {\"tfidf__max_features\": [3000],\n",
    "                         \"tfidf__ngram_range\": [(1,2)],\n",
    "                         \"tfidf__stop_words\": [\"english\"]}\n",
    "gs_tfidf_mnb = GridSearchCV(pipe_tfidf_mnb,\n",
    "                            param_grid = pipe_tfidf_mnb_params,\n",
    "                            cv = 5, n_jobs = -1)\n",
    "gs_tfidf_mnb.fit(X_train, y_train)\n",
    "gs_tfidf_mnb_model = gs_tfidf_mnb.best_estimator_\n",
    "gs_tfidf_mnb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf__max_features': 3000,\n",
       " 'tfidf__ngram_range': (1, 2),\n",
       " 'tfidf__stop_words': 'english'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# likely the best Naive Bayes model for Tfidf Vectorizer\n",
    "pipe_tfidf_gnb = Pipeline([(\"tfidf\", TfidfVectorizer()),\n",
    "                         (\"ft\", FunctionTransformer(lambda x: x.todense(), accept_sparse = True)),\n",
    "                         (\"gnb\", GaussianNB())])\n",
    "pipe_tfidf_gnb_params = {\"tfidf__max_features\": [3000],\n",
    "                         \"tfidf__ngram_range\": [(1,2)],\n",
    "                         \"tfidf__stop_words\": [\"english\"]}\n",
    "gs_tfidf_gnb = GridSearchCV(pipe_tfidf_gnb,\n",
    "                            param_grid = pipe_tfidf_gnb_params,\n",
    "                            cv = 5, n_jobs = -1)\n",
    "gs_tfidf_gnb.fit(X_train, y_train)\n",
    "gs_tfidf_gnb_model = gs_tfidf_gnb.best_estimator_\n",
    "gs_tfidf_gnb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knn__n_neighbors': 15,\n",
       " 'tfidf__max_features': 100,\n",
       " 'tfidf__ngram_range': (1, 1),\n",
       " 'tfidf__stop_words': None}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_tfidf_knn = Pipeline([(\"tfidf\", TfidfVectorizer()),\n",
    "                         (\"ft\", FunctionTransformer(lambda x: x.todense(), accept_sparse = True)),\n",
    "                         (\"knn\", KNeighborsClassifier())])\n",
    "pipe_tfidf_knn_params = {\"tfidf__max_features\": [100],\n",
    "                         \"tfidf__ngram_range\": [(1,1)],\n",
    "                         \"tfidf__stop_words\": [None],\n",
    "                         \"knn__n_neighbors\": [15]}\n",
    "gs_tfidf_knn = GridSearchCV(pipe_tfidf_knn,\n",
    "                            param_grid = pipe_tfidf_knn_params,\n",
    "                            cv = 5, n_jobs = -1)\n",
    "gs_tfidf_knn.fit(X_train, y_train)\n",
    "gs_tfidf_knn_model = gs_tfidf_knn.best_estimator_\n",
    "gs_tfidf_knn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dt__max_depth': 10,\n",
       " 'dt__min_samples_leaf': 3,\n",
       " 'dt__min_samples_split': 10,\n",
       " 'tfidf__max_features': 500,\n",
       " 'tfidf__ngram_range': (1, 1),\n",
       " 'tfidf__stop_words': None}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not likely optimal without bagging or boosting\n",
    "pipe_tfidf_dt = Pipeline([(\"tfidf\", TfidfVectorizer()),\n",
    "                          (\"ft\", FunctionTransformer(lambda x: x.todense(), accept_sparse = True)),\n",
    "                          (\"dt\", DecisionTreeClassifier())])\n",
    "pipe_tfidf_dt_params = {\"tfidf__max_features\": [500],\n",
    "                        \"tfidf__ngram_range\": [(1,1)],\n",
    "                        \"tfidf__stop_words\": [None],\n",
    "                        \"dt__max_depth\": [10],\n",
    "                        \"dt__min_samples_split\": [10],\n",
    "                        \"dt__min_samples_leaf\": [3]}\n",
    "gs_tfidf_dt = GridSearchCV(pipe_tfidf_dt,\n",
    "                          param_grid = pipe_tfidf_dt_params,\n",
    "                          cv = 5, n_jobs = -1)\n",
    "gs_tfidf_dt.fit(X_train, y_train)\n",
    "gs_tfidf_dt_model = gs_tfidf_dt.best_estimator_\n",
    "gs_tfidf_dt.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bag__base_estimator__max_depth': 10,\n",
       " 'bag__base_estimator__min_samples_leaf': 3,\n",
       " 'bag__base_estimator__min_samples_split': 10,\n",
       " 'bag__max_features': 0.9,\n",
       " 'bag__max_samples': 0.5,\n",
       " 'bag__n_estimators': 20,\n",
       " 'tfidf__max_features': 500,\n",
       " 'tfidf__ngram_range': (1, 1),\n",
       " 'tfidf__stop_words': None}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_tfidf_dt_bag = Pipeline([(\"tfidf\", TfidfVectorizer()),\n",
    "                              (\"ft\", FunctionTransformer(lambda x: x.todense(), accept_sparse = True)),\n",
    "                              (\"bag\", BaggingClassifier(base_estimator = DecisionTreeClassifier()))])\n",
    "pipe_tfidf_dt_bag_params = {\"bag__base_estimator__max_depth\": [10],\n",
    "                           \"bag__base_estimator__min_samples_leaf\": [3],\n",
    "                           \"bag__base_estimator__min_samples_split\": [10],\n",
    "                           'tfidf__max_features': [500],\n",
    "                           'tfidf__ngram_range': [(1, 1)],\n",
    "                           'tfidf__stop_words': [None],\n",
    "                           \"bag__n_estimators\": [20],\n",
    "                           \"bag__max_samples\": [.5],\n",
    "                           \"bag__max_features\": [.9]}\n",
    "gs_tfidf_dt_bag = GridSearchCV(pipe_tfidf_dt_bag,\n",
    "                              param_grid = pipe_tfidf_dt_bag_params,\n",
    "                              cv = 5, n_jobs = -1)\n",
    "gs_tfidf_dt_bag.fit(X_train, y_train)\n",
    "gs_tfidf_dt_bag_model = gs_tfidf_dt_bag.best_estimator_\n",
    "gs_tfidf_dt_bag.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 7000,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english',\n",
       " 'rf__max_depth': None,\n",
       " 'rf__n_estimators': 100}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_tfidf_rf = Pipeline([(\"tfidf\", TfidfVectorizer()),\n",
    "                          (\"ft\", FunctionTransformer(lambda x: x.todense(), accept_sparse = True)),\n",
    "                          (\"rf\", RandomForestClassifier())])\n",
    "pipe_tfidf_rf_params = {'tfidf__max_features': [500],\n",
    "                        'tfidf__ngram_range': [(1, 1)],\n",
    "                        'tfidf__stop_words': [None],\n",
    "                        \"rf__n_estimators\": [100],\n",
    "                        \"rf__max_depth\": [None]}\n",
    "gs_tfidf_rf = GridSearchCV(pipe_cvec_rf,\n",
    "                           param_grid = pipe_cvec_rf_params,\n",
    "                           cv = 5, n_jobs = -1)\n",
    "gs_tfidf_rf.fit(X_train, y_train)\n",
    "gs_tfidf_rf_model = gs_tfidf_rf.best_estimator_\n",
    "gs_tfidf_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 6000,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english',\n",
       " 'et__max_depth': None,\n",
       " 'et__n_estimators': 150}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_tfidf_et = Pipeline([(\"tfidf\", TfidfVectorizer()),\n",
    "                          (\"ft\", FunctionTransformer(lambda x: x.todense(), accept_sparse = True)),\n",
    "                          (\"et\", ExtraTreesClassifier())])\n",
    "pipe_tfidf_et_params = {'tfidf__max_features': [500],\n",
    "                        'tfidf__ngram_range': [(1, 1)],\n",
    "                        'tfidf__stop_words': [None],\n",
    "                        \"et__n_estimators\": [150],\n",
    "                        \"et__max_depth\": [None]}\n",
    "gs_tfidf_et = GridSearchCV(pipe_cvec_et,\n",
    "                           param_grid = pipe_cvec_et_params,\n",
    "                           cv = 5, n_jobs = -1)\n",
    "gs_tfidf_et.fit(X_train, y_train)\n",
    "gs_tfidf_et_model = gs_tfidf_et.best_estimator_\n",
    "gs_tfidf_et.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ada__base_estimator__max_depth': 2,\n",
       " 'ada__n_estimators': 150,\n",
       " 'tfidf__max_features': 500,\n",
       " 'tfidf__ngram_range': (1, 1),\n",
       " 'tfidf__stop_words': None}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_tfidf_ada = Pipeline([(\"tfidf\", TfidfVectorizer()),\n",
    "                           (\"ft\", FunctionTransformer(lambda x: x.todense(), accept_sparse = True)),\n",
    "                           (\"ada\", AdaBoostClassifier(base_estimator = DecisionTreeClassifier()))])\n",
    "pipe_tfidf_ada_params = {\"ada__base_estimator__max_depth\": [2],\n",
    "                         'tfidf__max_features': [500],\n",
    "                         'tfidf__ngram_range': [(1, 1)],\n",
    "                         'tfidf__stop_words': [None],\n",
    "                         \"ada__n_estimators\": [150]}\n",
    "gs_tfidf_ada = GridSearchCV(pipe_tfidf_ada,\n",
    "                           param_grid = pipe_tfidf_ada_params,\n",
    "                           cv = 5, n_jobs = -1)\n",
    "gs_tfidf_ada.fit(X_train, y_train)\n",
    "gs_tfidf_ada_model = gs_tfidf_ada.best_estimator_\n",
    "gs_tfidf_ada.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc__C': 10,\n",
       " 'tfidf__max_features': 500,\n",
       " 'tfidf__ngram_range': (1, 1),\n",
       " 'tfidf__stop_words': None}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_tfidf_svc = Pipeline([(\"tfidf\", TfidfVectorizer()),\n",
    "                           (\"ft\", FunctionTransformer(lambda x: x.todense(), accept_sparse = True)),\n",
    "                           (\"svc\", SVC(probability = True))])\n",
    "pipe_tfidf_svc_params = {'tfidf__max_features': [500],\n",
    "                         'tfidf__ngram_range': [(1, 1)],\n",
    "                         'tfidf__stop_words': [None],\n",
    "                         \"svc__C\": [10]}\n",
    "gs_tfidf_svc = GridSearchCV(pipe_tfidf_svc,\n",
    "                            param_grid = pipe_tfidf_svc_params,\n",
    "                            cv = 5, n_jobs = -1)\n",
    "gs_tfidf_svc.fit(X_train, y_train)\n",
    "gs_tfidf_svc_model = gs_tfidf_svc.best_estimator_\n",
    "gs_tfidf_svc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Cross-Validation Scores, Training Scores, and Test Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Extraction</th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Accuracy</th>\n",
       "      <th>Training Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CVEC</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.674434</td>\n",
       "      <td>0.879619</td>\n",
       "      <td>0.681078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CVEC</td>\n",
       "      <td>BNB</td>\n",
       "      <td>0.650384</td>\n",
       "      <td>0.726419</td>\n",
       "      <td>0.649034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CVEC</td>\n",
       "      <td>MNB</td>\n",
       "      <td>0.694854</td>\n",
       "      <td>0.808092</td>\n",
       "      <td>0.701170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CVEC</td>\n",
       "      <td>GNB</td>\n",
       "      <td>0.641991</td>\n",
       "      <td>0.718777</td>\n",
       "      <td>0.641404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CVEC</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.561315</td>\n",
       "      <td>0.635475</td>\n",
       "      <td>0.552899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CVEC</td>\n",
       "      <td>DT</td>\n",
       "      <td>0.599275</td>\n",
       "      <td>0.680070</td>\n",
       "      <td>0.592828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CVEC</td>\n",
       "      <td>DT_BAG</td>\n",
       "      <td>0.637105</td>\n",
       "      <td>0.727797</td>\n",
       "      <td>0.637080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CVEC</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.657273</td>\n",
       "      <td>0.985093</td>\n",
       "      <td>0.671160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CVEC</td>\n",
       "      <td>ET</td>\n",
       "      <td>0.664788</td>\n",
       "      <td>0.983465</td>\n",
       "      <td>0.665819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CVEC</td>\n",
       "      <td>DT_ADA</td>\n",
       "      <td>0.644871</td>\n",
       "      <td>0.759739</td>\n",
       "      <td>0.640641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CVEC</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.652386</td>\n",
       "      <td>0.961794</td>\n",
       "      <td>0.669379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TFIDF</td>\n",
       "      <td>LR</td>\n",
       "      <td>0.685709</td>\n",
       "      <td>0.812852</td>\n",
       "      <td>0.694812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TFIDF</td>\n",
       "      <td>BNB</td>\n",
       "      <td>0.647379</td>\n",
       "      <td>0.694476</td>\n",
       "      <td>0.642675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TFIDF</td>\n",
       "      <td>MNB</td>\n",
       "      <td>0.675060</td>\n",
       "      <td>0.784918</td>\n",
       "      <td>0.686419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TFIDF</td>\n",
       "      <td>GNB</td>\n",
       "      <td>0.642743</td>\n",
       "      <td>0.794689</td>\n",
       "      <td>0.640132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TFIDF</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.574970</td>\n",
       "      <td>0.650132</td>\n",
       "      <td>0.564598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TFIDF</td>\n",
       "      <td>DT</td>\n",
       "      <td>0.586371</td>\n",
       "      <td>0.648127</td>\n",
       "      <td>0.572991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TFIDF</td>\n",
       "      <td>DT_BAG</td>\n",
       "      <td>0.605287</td>\n",
       "      <td>0.691469</td>\n",
       "      <td>0.603510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TFIDF</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.652763</td>\n",
       "      <td>0.985093</td>\n",
       "      <td>0.666836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TFIDF</td>\n",
       "      <td>ET</td>\n",
       "      <td>0.662284</td>\n",
       "      <td>0.983465</td>\n",
       "      <td>0.667091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TFIDF</td>\n",
       "      <td>DT_ADA</td>\n",
       "      <td>0.608169</td>\n",
       "      <td>0.780659</td>\n",
       "      <td>0.621312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TFIDF</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.638606</td>\n",
       "      <td>0.977953</td>\n",
       "      <td>0.644710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature Extraction   Model  CV Accuracy  Training Accuracy  Test Accuracy\n",
       "0                CVEC      LR     0.674434           0.879619       0.681078\n",
       "1                CVEC     BNB     0.650384           0.726419       0.649034\n",
       "2                CVEC     MNB     0.694854           0.808092       0.701170\n",
       "3                CVEC     GNB     0.641991           0.718777       0.641404\n",
       "4                CVEC     KNN     0.561315           0.635475       0.552899\n",
       "5                CVEC      DT     0.599275           0.680070       0.592828\n",
       "6                CVEC  DT_BAG     0.637105           0.727797       0.637080\n",
       "7                CVEC      RF     0.657273           0.985093       0.671160\n",
       "8                CVEC      ET     0.664788           0.983465       0.665819\n",
       "9                CVEC  DT_ADA     0.644871           0.759739       0.640641\n",
       "10               CVEC     SVC     0.652386           0.961794       0.669379\n",
       "11              TFIDF      LR     0.685709           0.812852       0.694812\n",
       "12              TFIDF     BNB     0.647379           0.694476       0.642675\n",
       "13              TFIDF     MNB     0.675060           0.784918       0.686419\n",
       "14              TFIDF     GNB     0.642743           0.794689       0.640132\n",
       "15              TFIDF     KNN     0.574970           0.650132       0.564598\n",
       "16              TFIDF      DT     0.586371           0.648127       0.572991\n",
       "17              TFIDF  DT_BAG     0.605287           0.691469       0.603510\n",
       "18              TFIDF      RF     0.652763           0.985093       0.666836\n",
       "19              TFIDF      ET     0.662284           0.983465       0.667091\n",
       "20              TFIDF  DT_ADA     0.608169           0.780659       0.621312\n",
       "21              TFIDF     SVC     0.638606           0.977953       0.644710"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(index = range(0,22), columns = [\"Feature Extraction\", \"Model\", \"CV Accuracy\", \"Training Accuracy\", \"Test Accuracy\"])\n",
    "results_df[\"Feature Extraction\"] = [\"CVEC\", \"CVEC\", \"CVEC\", \"CVEC\", \"CVEC\", \"CVEC\", \"CVEC\", \"CVEC\", \"CVEC\", \"CVEC\", \"CVEC\",\n",
    "                                    \"TFIDF\", \"TFIDF\", \"TFIDF\", \"TFIDF\", \"TFIDF\", \"TFIDF\", \"TFIDF\", \"TFIDF\", \"TFIDF\", \"TFIDF\", \"TFIDF\"]\n",
    "results_df[\"Model\"] = [\"LR\", \"BNB\", \"MNB\", \"GNB\", \"KNN\", \"DT\", \"DT_BAG\", \"RF\", \"ET\", \"DT_ADA\", \"SVC\",\n",
    "                       \"LR\", \"BNB\", \"MNB\", \"GNB\", \"KNN\", \"DT\", \"DT_BAG\", \"RF\", \"ET\", \"DT_ADA\", \"SVC\"]\n",
    "results_df[\"CV Accuracy\"] = [gs_cvec_lr.best_score_, \n",
    "                             gs_cvec_bnb.best_score_, \n",
    "                             gs_cvec_mnb.best_score_, \n",
    "                             gs_cvec_gnb.best_score_, \n",
    "                             gs_cvec_knn.best_score_,\n",
    "                             gs_cvec_dt.best_score_,\n",
    "                             gs_cvec_dt_bag.best_score_,\n",
    "                             gs_cvec_rf.best_score_,\n",
    "                             gs_cvec_et.best_score_,\n",
    "                             gs_cvec_ada.best_score_,\n",
    "                             gs_cvec_svc.best_score_,\n",
    "                             gs_tfidf_lr.best_score_,\n",
    "                             gs_tfidf_bnb.best_score_,\n",
    "                             gs_tfidf_mnb.best_score_,\n",
    "                             gs_tfidf_gnb.best_score_,\n",
    "                             gs_tfidf_knn.best_score_,\n",
    "                             gs_tfidf_dt.best_score_,\n",
    "                             gs_tfidf_dt_bag.best_score_,\n",
    "                             gs_tfidf_rf.best_score_,\n",
    "                             gs_tfidf_et.best_score_,\n",
    "                             gs_tfidf_ada.best_score_,\n",
    "                             gs_tfidf_svc.best_score_]\n",
    "results_df[\"Training Accuracy\"] = [gs_cvec_lr_model.score(X_train, y_train),\n",
    "                                   gs_cvec_bnb_model.score(X_train, y_train),\n",
    "                                   gs_cvec_mnb_model.score(X_train, y_train),\n",
    "                                   gs_cvec_gnb_model.score(X_train, y_train),\n",
    "                                   gs_cvec_knn_model.score(X_train, y_train),\n",
    "                                   gs_cvec_dt_model.score(X_train, y_train),\n",
    "                                   gs_cvec_dt_bag_model.score(X_train, y_train),\n",
    "                                   gs_cvec_rf_model.score(X_train, y_train),\n",
    "                                   gs_cvec_et_model.score(X_train, y_train),\n",
    "                                   gs_cvec_ada_model.score(X_train, y_train),\n",
    "                                   gs_cvec_svc_model.score(X_train, y_train),\n",
    "                                   gs_tfidf_lr_model.score(X_train, y_train),\n",
    "                                   gs_tfidf_bnb_model.score(X_train, y_train),\n",
    "                                   gs_tfidf_mnb_model.score(X_train, y_train),\n",
    "                                   gs_tfidf_gnb_model.score(X_train, y_train),\n",
    "                                   gs_tfidf_knn_model.score(X_train, y_train),\n",
    "                                   gs_tfidf_dt_model.score(X_train, y_train),\n",
    "                                   gs_tfidf_dt_bag_model.score(X_train, y_train),\n",
    "                                   gs_tfidf_rf_model.score(X_train, y_train),\n",
    "                                   gs_tfidf_et_model.score(X_train, y_train),\n",
    "                                   gs_tfidf_ada_model.score(X_train, y_train),\n",
    "                                   gs_tfidf_svc_model.score(X_train, y_train)]\n",
    "results_df[\"Test Accuracy\"] = [gs_cvec_lr_model.score(X_test, y_test),\n",
    "                               gs_cvec_bnb_model.score(X_test, y_test),\n",
    "                               gs_cvec_mnb_model.score(X_test, y_test),\n",
    "                               gs_cvec_gnb_model.score(X_test, y_test),\n",
    "                               gs_cvec_knn_model.score(X_test, y_test),\n",
    "                               gs_cvec_dt_model.score(X_test, y_test),\n",
    "                               gs_cvec_dt_bag_model.score(X_test, y_test),\n",
    "                               gs_cvec_rf_model.score(X_test, y_test),\n",
    "                               gs_cvec_et_model.score(X_test, y_test),\n",
    "                               gs_cvec_ada_model.score(X_test, y_test),\n",
    "                               gs_cvec_svc_model.score(X_test, y_test),\n",
    "                               gs_tfidf_lr_model.score(X_test, y_test),\n",
    "                               gs_tfidf_bnb_model.score(X_test, y_test),\n",
    "                               gs_tfidf_mnb_model.score(X_test, y_test),\n",
    "                               gs_tfidf_gnb_model.score(X_test, y_test),\n",
    "                               gs_tfidf_knn_model.score(X_test, y_test),\n",
    "                               gs_tfidf_dt_model.score(X_test, y_test),\n",
    "                               gs_tfidf_dt_bag_model.score(X_test, y_test),\n",
    "                               gs_tfidf_rf_model.score(X_test, y_test),\n",
    "                               gs_tfidf_et_model.score(X_test, y_test),\n",
    "                               gs_tfidf_ada_model.score(X_test, y_test),\n",
    "                               gs_tfidf_svc_model.score(X_test, y_test)]\n",
    "results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All models were overfitted (higher training score than test score), so I selected the model with the highest test score.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The function transformer can't be saved by pickling, so it will have to be re-fitted in the next notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(max_features = 7500, ngram_range = (1,1), stop_words = None)\n",
    "vec_fitted = cvec.fit(X_train)\n",
    "X_train = cvec.transform(X_train)\n",
    "X_test = cvec.transform(X_test)\n",
    "\n",
    "ft = FunctionTransformer(lambda x: x.todense(), accept_sparse = True)\n",
    "ft_fitted = ft.fit(X_train)\n",
    "X_train = ft.transform(X_train)\n",
    "X_test = ft.transform(X_test)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "best_model = mnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8080921959163222\n",
      "0.7011698880976602\n"
     ]
    }
   ],
   "source": [
    "print(best_model.score(X_train, y_train))\n",
    "print(best_model.score(X_test, y_test))\n",
    "# same as the Pipeline above, as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vec_fitted, open('../models/vec_fitted.joblib', 'wb'))\n",
    "\n",
    "pickle.dump(best_model, open('../models/best_model.joblib', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See Notebook 5 for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
